{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Predict the wellbeing of shanghainese communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.read_pickle(\"df_prediction.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_transportation_scaled</th>\n",
       "      <th>nb_shopping_scaled</th>\n",
       "      <th>nb_restaurant_scaled</th>\n",
       "      <th>nb_scenicSpot_scaled</th>\n",
       "      <th>nb_stadiumAndGym_scaled</th>\n",
       "      <th>nb_mobike_scaled</th>\n",
       "      <th>green_space_scaled</th>\n",
       "      <th>happiness_equalCoff</th>\n",
       "      <th>happiness_clean</th>\n",
       "      <th>happiness_smell</th>\n",
       "      <th>happiness_noise</th>\n",
       "      <th>happiness_perso</th>\n",
       "      <th>happiness_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.757151</td>\n",
       "      <td>-0.598362</td>\n",
       "      <td>-0.721806</td>\n",
       "      <td>-0.405934</td>\n",
       "      <td>-0.747588</td>\n",
       "      <td>-0.808407</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.838055</td>\n",
       "      <td>-0.682104</td>\n",
       "      <td>-0.801698</td>\n",
       "      <td>-0.404075</td>\n",
       "      <td>-0.792245</td>\n",
       "      <td>-0.808407</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.905242</td>\n",
       "      <td>-0.692630</td>\n",
       "      <td>-0.810939</td>\n",
       "      <td>-0.427699</td>\n",
       "      <td>-0.807475</td>\n",
       "      <td>-0.808395</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.911484</td>\n",
       "      <td>-0.694507</td>\n",
       "      <td>-0.783498</td>\n",
       "      <td>-0.381704</td>\n",
       "      <td>-0.775861</td>\n",
       "      <td>-0.808336</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.905943</td>\n",
       "      <td>-0.688400</td>\n",
       "      <td>-0.805164</td>\n",
       "      <td>-0.421503</td>\n",
       "      <td>-0.800932</td>\n",
       "      <td>-0.808370</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_transportation_scaled  nb_shopping_scaled  nb_restaurant_scaled  \\\n",
       "0                 -0.757151           -0.598362             -0.721806   \n",
       "1                 -0.838055           -0.682104             -0.801698   \n",
       "2                 -0.905242           -0.692630             -0.810939   \n",
       "3                 -0.911484           -0.694507             -0.783498   \n",
       "4                 -0.905943           -0.688400             -0.805164   \n",
       "\n",
       "   nb_scenicSpot_scaled  nb_stadiumAndGym_scaled  nb_mobike_scaled  \\\n",
       "0             -0.405934                -0.747588         -0.808407   \n",
       "1             -0.404075                -0.792245         -0.808407   \n",
       "2             -0.427699                -0.807475         -0.808395   \n",
       "3             -0.381704                -0.775861         -0.808336   \n",
       "4             -0.421503                -0.800932         -0.808370   \n",
       "\n",
       "   green_space_scaled  happiness_equalCoff  happiness_clean  happiness_smell  \\\n",
       "0            0.265348             1.666667         2.428571         1.285714   \n",
       "1            0.265348             1.333333         2.095238         0.952381   \n",
       "2            0.265348             1.666667         2.428571         1.285714   \n",
       "3            0.265348             1.333333         1.714286         1.142857   \n",
       "4            0.265348             1.000000         1.571429         1.000000   \n",
       "\n",
       "   happiness_noise  happiness_perso  happiness_other  \n",
       "0         1.285714         1.600000         1.444444  \n",
       "1         0.952381         1.266667         1.111111  \n",
       "2         1.285714         1.600000         1.444444  \n",
       "3         1.142857         1.300000         1.222222  \n",
       "4         0.428571         1.100000         0.666667  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       2.062544\n",
       "std        0.314851\n",
       "min        1.380952\n",
       "25%        1.836735\n",
       "50%        2.035714\n",
       "75%        2.285714\n",
       "max        3.000000\n",
       "Name: happiness_clean, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict['happiness_clean'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Happiness when clean, smell, noise have the same coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_predict[['nb_transportation_scaled', 'nb_shopping_scaled', 'nb_restaurant_scaled', 'nb_scenicSpot_scaled', 'nb_stadiumAndGym_scaled', 'nb_mobike_scaled', 'green_space_scaled']] #features\n",
    "Y_coeff = df_predict['happiness_equalCoff'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       1.389260\n",
       "std        0.183787\n",
       "min        1.000000\n",
       "25%        1.333333\n",
       "50%        1.333333\n",
       "75%        1.500000\n",
       "max        1.666667\n",
       "Name: happiness_equalCoff, dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_coeff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_coeff = pd.DataFrame.copy(Y_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_coeff = Y_coeff.apply(lambda x:\"Very unhappy\" if x < 1.165 else \n",
    "        \"Unhappy\" if (x >= 1.165 and x < 1.33) else\n",
    "        \"Happy\" if (x >= 1.33 and x < 1.495) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(8, \"class_samecoeff\", Z_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_samecoeff\n",
       "Happy           52\n",
       "Unhappy         21\n",
       "Very happy      45\n",
       "Very unhappy    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_samecoeff').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Happiness when CLEAN has more importance than noise, smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_clean = df_predict['happiness_clean'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       2.062544\n",
       "std        0.314851\n",
       "min        1.380952\n",
       "25%        1.836735\n",
       "50%        2.035714\n",
       "75%        2.285714\n",
       "max        3.000000\n",
       "Name: happiness_clean, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_clean = pd.DataFrame.copy(Y_clean)\n",
    "Z_clean = Y_clean.apply(lambda x:\"Very unhappy\" if x < 1.785714 else \n",
    "        \"Unhappy\" if (x >= 1.1785714 and x < 2.190476) else\n",
    "        \"Happy\" if (x >= 2.190476 and x < 2.595238) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(10, \"class_clean\", Z_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_clean\n",
       "Happy           40\n",
       "Unhappy         55\n",
       "Very happy       5\n",
       "Very unhappy    29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_clean').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Happiness when SMELL has more importance than clean, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_smell = df_predict['happiness_smell'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       1.083657\n",
       "std        0.171013\n",
       "min        0.428571\n",
       "25%        1.000000\n",
       "50%        1.142857\n",
       "75%        1.214286\n",
       "max        1.285714\n",
       "Name: happiness_smell, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_smell.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2142857142857143\n",
      "0.6428571428571428\n",
      "0.8571428571428572\n",
      "1.0714285714285714\n"
     ]
    }
   ],
   "source": [
    "print((Y_smell.max()-Y_smell.min())/4)\n",
    "print(Y_smell.min() + ((Y_smell.max()-Y_smell.min())/4))\n",
    "print(Y_smell.min() + ((Y_smell.max()-Y_smell.min())/4)*2)\n",
    "print(Y_smell.min() + ((Y_smell.max()-Y_smell.min())/4)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_smell = pd.DataFrame.copy(Y_smell)\n",
    "Z_smell = Y_smell.apply(lambda x:\"Very unhappy\" if x < 0.6428571428571428 else \n",
    "        \"Unhappy\" if (x >= 0.6428571428571428 and x < 0.8571428571428572) else\n",
    "        \"Happy\" if (x >= 0.8571428571428572 and x < 1.0714285714285714) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(12, \"class_smell\", Z_smell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_smell\n",
       "Happy           33\n",
       "Unhappy         14\n",
       "Very happy      80\n",
       "Very unhappy     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_smell').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Happiness when NOISE has more importance than clean, smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_noise = df_predict['happiness_noise'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       1.021580\n",
       "std        0.234248\n",
       "min        0.428571\n",
       "25%        0.904762\n",
       "50%        1.102041\n",
       "75%        1.196429\n",
       "max        1.285714\n",
       "Name: happiness_noise, dtype: float64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_noise.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2142857142857143\n",
      "0.6428571428571428\n",
      "0.8571428571428572\n",
      "1.0714285714285714\n"
     ]
    }
   ],
   "source": [
    "print((Y_noise.max()-Y_noise.min())/4)\n",
    "print(Y_noise.min() + ((Y_noise.max()-Y_noise.min())/4))\n",
    "print(Y_noise.min() + ((Y_noise.max()-Y_noise.min())/4)*2)\n",
    "print(Y_noise.min() + ((Y_noise.max()-Y_noise.min())/4)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_noise = pd.DataFrame.copy(Y_noise)\n",
    "Z_noise = Y_noise.apply(lambda x:\"Very unhappy\" if x < 0.6428571428571428 else \n",
    "        \"Unhappy\" if (x >= 0.6428571428571428 and x < 0.8571428571428572) else\n",
    "        \"Happy\" if (x >= 0.8571428571428572 and x < 1.0714285714285714) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(14, \"class_noise\", Z_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_noise\n",
       "Happy           30\n",
       "Unhappy         13\n",
       "Very happy      73\n",
       "Very unhappy    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_noise').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Happiness - personnal opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_perso = df_predict['happiness_perso'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    129.000000\n",
       "mean       1.346643\n",
       "std        0.177887\n",
       "min        0.800000\n",
       "25%        1.250000\n",
       "50%        1.325000\n",
       "75%        1.450000\n",
       "max        1.700000\n",
       "Name: happiness_perso, dtype: float64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_perso.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22499999999999998\n",
      "1.025\n",
      "1.25\n",
      "1.475\n"
     ]
    }
   ],
   "source": [
    "print((Y_perso.max()-Y_perso.min())/4)\n",
    "print(Y_perso.min() + ((Y_perso.max()-Y_perso.min())/4))\n",
    "print(Y_perso.min() + ((Y_perso.max()-Y_perso.min())/4)*2)\n",
    "print(Y_perso.min() + ((Y_perso.max()-Y_perso.min())/4)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_perso = pd.DataFrame.copy(Y_perso)\n",
    "Z_perso = Y_perso.apply(lambda x:\"Very unhappy\" if x < 1.025 else \n",
    "        \"Unhappy\" if (x >= 1.025 and x < 1.25) else\n",
    "        \"Happy\" if (x >= 1.25 and x < 1.475) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(16, \"class_perso\", Z_perso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_perso\n",
       "Happy           66\n",
       "Unhappy         25\n",
       "Very happy      32\n",
       "Very unhappy     6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_perso').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Happiness - arbitary choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_other = df_predict['happiness_other'] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19444444444444445\n",
      "0.861111111111111\n",
      "1.0555555555555556\n",
      "1.25\n"
     ]
    }
   ],
   "source": [
    "print((Y_other.max()-Y_other.min())/4)\n",
    "print(Y_other.min() + ((Y_other.max()-Y_other.min())/4))\n",
    "print(Y_other.min() + ((Y_other.max()-Y_other.min())/4)*2)\n",
    "print(Y_other.min() + ((Y_other.max()-Y_other.min())/4)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_other = pd.DataFrame.copy(Y_other)\n",
    "Z_other = Y_other.apply(lambda x:\"Very unhappy\" if x < 0.861111111111111 else \n",
    "        \"Unhappy\" if (x >= 0.861111111111111 and x < 1.0555555555555556) else\n",
    "        \"Happy\" if (x >= 1.0555555555555556 and x < 1.25) else\n",
    "        \"Very happy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.insert(18, \"class_other\", Z_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_other\n",
       "Happy           53\n",
       "Unhappy         16\n",
       "Very happy      49\n",
       "Very unhappy    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.groupby('class_other').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_transportation_scaled</th>\n",
       "      <th>nb_shopping_scaled</th>\n",
       "      <th>nb_restaurant_scaled</th>\n",
       "      <th>nb_scenicSpot_scaled</th>\n",
       "      <th>nb_stadiumAndGym_scaled</th>\n",
       "      <th>nb_mobike_scaled</th>\n",
       "      <th>green_space_scaled</th>\n",
       "      <th>happiness_equalCoff</th>\n",
       "      <th>class_samecoeff</th>\n",
       "      <th>happiness_clean</th>\n",
       "      <th>class_clean</th>\n",
       "      <th>happiness_smell</th>\n",
       "      <th>class_smell</th>\n",
       "      <th>happiness_noise</th>\n",
       "      <th>class_noise</th>\n",
       "      <th>happiness_perso</th>\n",
       "      <th>class_perso</th>\n",
       "      <th>happiness_other</th>\n",
       "      <th>class_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.757151</td>\n",
       "      <td>-0.598362</td>\n",
       "      <td>-0.721806</td>\n",
       "      <td>-0.405934</td>\n",
       "      <td>-0.747588</td>\n",
       "      <td>-0.808407</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>Very happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.838055</td>\n",
       "      <td>-0.682104</td>\n",
       "      <td>-0.801698</td>\n",
       "      <td>-0.404075</td>\n",
       "      <td>-0.792245</td>\n",
       "      <td>-0.808407</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2.095238</td>\n",
       "      <td>Unhappy</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.266667</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.905242</td>\n",
       "      <td>-0.692630</td>\n",
       "      <td>-0.810939</td>\n",
       "      <td>-0.427699</td>\n",
       "      <td>-0.807475</td>\n",
       "      <td>-0.808395</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>Very happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.911484</td>\n",
       "      <td>-0.694507</td>\n",
       "      <td>-0.783498</td>\n",
       "      <td>-0.381704</td>\n",
       "      <td>-0.775861</td>\n",
       "      <td>-0.808336</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>Very unhappy</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>Very happy</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Happy</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.905943</td>\n",
       "      <td>-0.688400</td>\n",
       "      <td>-0.805164</td>\n",
       "      <td>-0.421503</td>\n",
       "      <td>-0.800932</td>\n",
       "      <td>-0.808370</td>\n",
       "      <td>0.265348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Very unhappy</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>Very unhappy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>Very unhappy</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>Unhappy</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Very unhappy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_transportation_scaled  nb_shopping_scaled  nb_restaurant_scaled  \\\n",
       "0                 -0.757151           -0.598362             -0.721806   \n",
       "1                 -0.838055           -0.682104             -0.801698   \n",
       "2                 -0.905242           -0.692630             -0.810939   \n",
       "3                 -0.911484           -0.694507             -0.783498   \n",
       "4                 -0.905943           -0.688400             -0.805164   \n",
       "\n",
       "   nb_scenicSpot_scaled  nb_stadiumAndGym_scaled  nb_mobike_scaled  \\\n",
       "0             -0.405934                -0.747588         -0.808407   \n",
       "1             -0.404075                -0.792245         -0.808407   \n",
       "2             -0.427699                -0.807475         -0.808395   \n",
       "3             -0.381704                -0.775861         -0.808336   \n",
       "4             -0.421503                -0.800932         -0.808370   \n",
       "\n",
       "   green_space_scaled  happiness_equalCoff class_samecoeff  happiness_clean  \\\n",
       "0            0.265348             1.666667      Very happy         2.428571   \n",
       "1            0.265348             1.333333           Happy         2.095238   \n",
       "2            0.265348             1.666667      Very happy         2.428571   \n",
       "3            0.265348             1.333333           Happy         1.714286   \n",
       "4            0.265348             1.000000    Very unhappy         1.571429   \n",
       "\n",
       "    class_clean  happiness_smell class_smell  happiness_noise   class_noise  \\\n",
       "0         Happy         1.285714  Very happy         1.285714    Very happy   \n",
       "1       Unhappy         0.952381       Happy         0.952381         Happy   \n",
       "2         Happy         1.285714  Very happy         1.285714    Very happy   \n",
       "3  Very unhappy         1.142857  Very happy         1.142857    Very happy   \n",
       "4  Very unhappy         1.000000       Happy         0.428571  Very unhappy   \n",
       "\n",
       "   happiness_perso class_perso  happiness_other   class_other  \n",
       "0         1.600000  Very happy         1.444444    Very happy  \n",
       "1         1.266667       Happy         1.111111         Happy  \n",
       "2         1.600000  Very happy         1.444444    Very happy  \n",
       "3         1.300000       Happy         1.222222         Happy  \n",
       "4         1.100000     Unhappy         0.666667  Very unhappy  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.to_pickle(\"df_prediction_classification.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Target: Happiness_samecoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_coeff_train, Z_coeff_test = train_test_split(X, Z_coeff, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,4,6,8,10,20,40,100]}\n",
    "search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv= ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_coeff_train)\n",
    "print(\"Best parameters\" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5128205128205128"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=search.best_params_['max_depth'])\n",
    "clf = clf.fit(X_train, Z_coeff_train)\n",
    "prediction = clf.predict(X_test)\n",
    "np.mean(prediction == Z_coeff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.53      0.89      0.67        18\n",
      "     Unhappy       0.00      0.00      0.00         5\n",
      "  Very happy       0.57      0.31      0.40        13\n",
      "Very unhappy       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.51        39\n",
      "   macro avg       0.28      0.30      0.27        39\n",
      "weighted avg       0.44      0.51      0.44        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_coeff_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3846153846153846"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Z_coeff, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 12, 'n_estimators': 12}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [12,14, 16], 'n_estimators' : [12,14,16]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_coeff)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=3, n_estimators = 3)\n",
    "rfc = rfc.fit(X_train, Z_coeff_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "np.mean(prediction == Z_coeff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.53      0.89      0.67        18\n",
      "     Unhappy       0.00      0.00      0.00         5\n",
      "  Very happy       0.57      0.31      0.40        13\n",
      "Very unhappy       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.51        39\n",
      "   macro avg       0.28      0.30      0.27        39\n",
      "weighted avg       0.44      0.51      0.44        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_coeff_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36923076923076925"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, X, Z_coeff, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'n_neighbors': 12}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [12,25,30]}\n",
    "search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_coeff)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41025641025641024"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn = knn.fit(X_train, Z_coeff_train)\n",
    "prediction = knn.predict(X_test)\n",
    "np.mean(prediction == Z_coeff_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3356043956043956"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "n_neighbors = 30\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "scores = cross_val_score(knn, X, Z_coeff, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = {'C': [900,950,1000]}\n",
    "search = GridSearchCV(LinearSVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_coeff_train)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=1000)\n",
    "svc = svc.fit(X_train, Z_coeff_train)\n",
    "prediction = svc.predict(X_test)\n",
    "np.mean(prediction == Z_coeff_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Target: Happiness_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_clean_train, Z_clean_test = train_test_split(X, Z_clean, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,4,6,8,10,20,40,100]}\n",
    "search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv= ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_clean_train)\n",
    "print(\"Best parameters\" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=search.best_params_['max_depth'])\n",
    "clf = clf.fit(X_train, Z_clean_train)\n",
    "prediction = clf.predict(X_test)\n",
    "np.mean(prediction == Z_clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.33      0.38      0.35         8\n",
      "     Unhappy       0.56      0.78      0.65        18\n",
      "  Very happy       0.00      0.00      0.00         1\n",
      "Very unhappy       0.20      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.46        39\n",
      "   macro avg       0.27      0.31      0.28        39\n",
      "weighted avg       0.39      0.46      0.41        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_clean_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49230769230769234"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Z_clean, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 12, 'n_estimators': 12}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [12,14, 16], 'n_estimators' : [12,14,16]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_clean)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=12, n_estimators = 12)\n",
    "rfc = rfc.fit(X_train, Z_clean_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "np.mean(prediction == Z_clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.50      0.50      0.50        12\n",
      "     Unhappy       0.67      0.78      0.72        18\n",
      "  Very happy       0.00      0.00      0.00         1\n",
      "Very unhappy       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.62        39\n",
      "   macro avg       0.46      0.44      0.45        39\n",
      "weighted avg       0.60      0.62      0.60        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_clean_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6461538461538462"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, X, Z_clean, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'n_neighbors': 12}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [12,25,30]}\n",
    "search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_clean)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "knn = knn.fit(X_train, Z_clean_train)\n",
    "prediction = knn.predict(X_test)\n",
    "np.mean(prediction == Z_clean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.43      0.25      0.32        12\n",
      "     Unhappy       0.67      0.78      0.72        18\n",
      "  Very happy       0.00      0.00      0.00         1\n",
      "Very unhappy       0.36      0.50      0.42         8\n",
      "\n",
      "    accuracy                           0.54        39\n",
      "   macro avg       0.36      0.38      0.36        39\n",
      "weighted avg       0.51      0.54      0.51        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_clean_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4338461538461538"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "n_neighbors = 30\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "scores = cross_val_score(knn, X, Z_clean, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 950}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = {'C': [900,950,1000]}\n",
    "search = GridSearchCV(LinearSVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_clean_train)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=950)\n",
    "svc = svc.fit(X_train, Z_clean_train)\n",
    "prediction = svc.predict(X_test)\n",
    "np.mean(prediction == Z_clean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Target: Happiness_smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_smell_train, Z_smell_test = train_test_split(X, Z_smell, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,4,6,8,10,20,40,100]}\n",
    "search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv= ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_smell_train)\n",
    "print(\"Best parameters\" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897435897435898"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=search.best_params_['max_depth'])\n",
    "clf = clf.fit(X_train, Z_smell_train)\n",
    "prediction = clf.predict(X_test)\n",
    "np.mean(prediction == Z_smell_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.00      0.00      0.00        10\n",
      "     Unhappy       0.00      0.00      0.00         5\n",
      "  Very happy       0.59      1.00      0.74        23\n",
      "Very unhappy       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.15      0.25      0.19        39\n",
      "weighted avg       0.35      0.59      0.44        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6307692307692307"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Z_smell, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 12, 'n_estimators': 14}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [10,12,20], 'n_estimators' : [12,14,16]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_smell)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4358974358974359"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=12, n_estimators = 14)\n",
    "rfc = rfc.fit(X_train, Z_smell_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "np.mean(prediction == Z_smell_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.23      0.30      0.26        10\n",
      "     Unhappy       0.33      0.20      0.25         5\n",
      "  Very happy       0.57      0.57      0.57        23\n",
      "Very unhappy       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44        39\n",
      "   macro avg       0.28      0.27      0.27        39\n",
      "weighted avg       0.44      0.44      0.43        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.476923076923077"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, X, Z_smell, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'n_neighbors': 25}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [20,25,30]}\n",
    "search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_smell)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5897435897435898"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn = knn.fit(X_train, Z_smell_train)\n",
    "prediction = knn.predict(X_test)\n",
    "np.mean(prediction == Z_smell_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.00      0.00      0.00        10\n",
      "     Unhappy       0.00      0.00      0.00         5\n",
      "  Very happy       0.59      1.00      0.74        23\n",
      "Very unhappy       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.59        39\n",
      "   macro avg       0.15      0.25      0.19        39\n",
      "weighted avg       0.35      0.59      0.44        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6214472934472934"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "n_neighbors = 30\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "scores = cross_val_score(knn, X, Z_smell, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = {'C': [10,40,50]}\n",
    "search = GridSearchCV(LinearSVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_smell_train)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5641025641025641"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=10)\n",
    "svc = svc.fit(X_train, Z_smell_train)\n",
    "prediction = svc.predict(X_test)\n",
    "np.mean(prediction == Z_smell_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Target: Happiness_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_noise_train, Z_noise_test = train_test_split(X, Z_noise, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,4,6,8,10,20,40,100]}\n",
    "search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv= ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_noise_train)\n",
    "print(\"Best parameters\" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2564102564102564"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=search.best_params_['max_depth'])\n",
    "clf = clf.fit(X_train, Z_noise_train)\n",
    "prediction = clf.predict(X_test)\n",
    "np.mean(prediction == Z_noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.00      0.00      0.00        10\n",
      "     Unhappy       0.29      0.40      0.33         5\n",
      "  Very happy       0.00      0.00      0.00        23\n",
      "Very unhappy       0.03      1.00      0.06         1\n",
      "\n",
      "    accuracy                           0.08        39\n",
      "   macro avg       0.08      0.35      0.10        39\n",
      "weighted avg       0.04      0.08      0.04        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49230769230769234"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Z_noise, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 20, 'n_estimators': 16}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [10,12,20], 'n_estimators' : [12,14,16]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_noise)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4358974358974359"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=20, n_estimators = 16)\n",
    "rfc = rfc.fit(X_train, Z_noise_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "np.mean(prediction == Z_noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.50      0.20      0.29        10\n",
      "     Unhappy       0.10      0.40      0.16         5\n",
      "  Very happy       0.00      0.00      0.00        23\n",
      "Very unhappy       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.10        39\n",
      "   macro avg       0.15      0.15      0.11        39\n",
      "weighted avg       0.14      0.10      0.09        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4153846153846154"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, X, Z_noise, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'n_neighbors': 25}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [20,25,30]}\n",
    "search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_noise)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "knn = knn.fit(X_train, Z_noise_train)\n",
    "prediction = knn.predict(X_test)\n",
    "np.mean(prediction == Z_noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.00      0.00      0.00        10\n",
      "     Unhappy       0.13      0.60      0.21         5\n",
      "  Very happy       0.00      0.00      0.00        23\n",
      "Very unhappy       0.06      1.00      0.12         1\n",
      "\n",
      "    accuracy                           0.10        39\n",
      "   macro avg       0.05      0.40      0.08        39\n",
      "weighted avg       0.02      0.10      0.03        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4874074074074074"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "n_neighbors = 25\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "scores = cross_val_score(knn, X, Z_noise, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = {'C': [10,20,40]}\n",
    "search = GridSearchCV(LinearSVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_noise_train)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=10)\n",
    "svc = svc.fit(X_train, Z_noise_train)\n",
    "prediction = svc.predict(X_test)\n",
    "np.mean(prediction == Z_noise_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.00      0.00      0.00        10\n",
      "     Unhappy       0.09      0.20      0.13         5\n",
      "  Very happy       0.00      0.00      0.00        23\n",
      "Very unhappy       0.04      1.00      0.07         1\n",
      "\n",
      "    accuracy                           0.05        39\n",
      "   macro avg       0.03      0.30      0.05        39\n",
      "weighted avg       0.01      0.05      0.02        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_smell_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Target: Happiness_perso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Z_perso_train, Z_perso_test = train_test_split(X, Z_perso, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters{'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,4,6,8,10,20,40,100]}\n",
    "search = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, cv= ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_perso_train)\n",
    "print(\"Best parameters\" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=search.best_params_['max_depth'])\n",
    "clf = clf.fit(X_train, Z_perso_train)\n",
    "prediction = clf.predict(X_test)\n",
    "np.mean(prediction == Z_perso_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.49      1.00      0.66        19\n",
      "     Unhappy       0.00      0.00      0.00         8\n",
      "  Very happy       0.00      0.00      0.00        10\n",
      "Very unhappy       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.49        39\n",
      "   macro avg       0.12      0.25      0.16        39\n",
      "weighted avg       0.24      0.49      0.32        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_perso_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4153846153846154"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X, Z_perso, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_depth': 20, 'n_estimators': 14}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [10,12,20], 'n_estimators' : [12,14,16]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_perso)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41025641025641024"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth=20, n_estimators = 14)\n",
    "rfc = rfc.fit(X_train, Z_perso_train)\n",
    "prediction = rfc.predict(X_test)\n",
    "np.mean(prediction == Z_perso_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.47      0.74      0.57        19\n",
      "     Unhappy       0.00      0.00      0.00         8\n",
      "  Very happy       0.14      0.10      0.12        10\n",
      "Very unhappy       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.41        39\n",
      "   macro avg       0.28      0.33      0.30        39\n",
      "weighted avg       0.29      0.41      0.33        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_perso_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rfc, X, Z_perso, cv=ShuffleSplit(n_splits=5))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'n_neighbors': 30}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_neighbors': [20,25,30]}\n",
    "search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X, Z_perso)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48717948717948717"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn = knn.fit(X_train, Z_perso_train)\n",
    "prediction = knn.predict(X_test)\n",
    "np.mean(prediction == Z_perso_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.49      1.00      0.66        19\n",
      "     Unhappy       0.00      0.00      0.00         8\n",
      "  Very happy       0.00      0.00      0.00        10\n",
      "Very unhappy       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.49        39\n",
      "   macro avg       0.12      0.25      0.16        39\n",
      "weighted avg       0.24      0.49      0.32        39\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_perso_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.472"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "n_neighbors = 30\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
    "scores = cross_val_score(knn, X, Z_perso, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "param_grid = {'C': [10,20,40]}\n",
    "search = GridSearchCV(LinearSVC(), param_grid, cv=ShuffleSplit(n_splits=5))\n",
    "search.fit(X_train, Z_perso_train)\n",
    "print(\"Best parameters \" + str(search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aurelie\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38461538461538464"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(C=10)\n",
    "svc = svc.fit(X_train, Z_perso_train)\n",
    "prediction = svc.predict(X_test)\n",
    "np.mean(prediction == Z_perso_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Happy       0.48      0.74      0.58        19\n",
      "     Unhappy       0.00      0.00      0.00         8\n",
      "  Very happy       0.20      0.10      0.13        10\n",
      "Very unhappy       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38        39\n",
      "   macro avg       0.17      0.21      0.18        39\n",
      "weighted avg       0.29      0.38      0.32        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: ')\n",
    "print(classification_report(Z_perso_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
